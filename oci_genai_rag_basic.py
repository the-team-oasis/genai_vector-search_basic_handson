import sys
import configparser
import oracledb
import io
import locale
import json
import argparse
from langchain_community.llms import OCIGenAI 
from langchain_community.document_loaders import PyPDFLoader
from langchain_core.prompts import PromptTemplate
from langchain_community.embeddings import OCIGenAIEmbeddings
from langchain_community.vectorstores import oraclevs
from langchain_community.vectorstores.oraclevs import OracleVS
from langchain_community.document_loaders.oracleai import OracleTextSplitter
from langchain_community.document_loaders.oracleai import OracleDocLoader
from langchain_community.vectorstores.utils import DistanceStrategy
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough
from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI

# UTF-8 ì¸ì½”ë”© ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')

# ë¡œì¼€ì¼ ì„¤ì •
try:
    locale.setlocale(locale.LC_ALL, 'ko_KR.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
    except:
        pass

def load_configs(db_config_path, llm_config_path):
    """ì„¤ì • íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë¡œë“œ
    with open(db_config_path, "r", encoding="utf-8") as config_file:
        config = json.load(config_file)

    # LLM íŒŒë¼ë¯¸í„° ì„¤ì • ë¡œë“œ
    with open(llm_config_path, "r", encoding="utf-8") as llm_config_file:
        llm_config = json.load(llm_config_file)

    return config, llm_config

def parse_arguments():
    """ëª…ë ¹í–‰ ì¸ìë¥¼ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='PDF AI Search Application with Oracle Vector Store')
    parser.add_argument('--db-config', default='db_config.json', 
                       help='ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: db_config.json)')
    parser.add_argument('--llm-config', default='llm_parameter_config.json', 
                       help='LLM íŒŒë¼ë¯¸í„° ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: llm_parameter_config.json)')
    parser.add_argument('question', help='ì§ˆë¬¸')
    return parser.parse_args()

# ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
args = parse_arguments()

# ì„¤ì • íŒŒì¼ ë¡œë“œ
config, llm_config = load_configs(args.db_config, args.llm_config)

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì¶”ì¶œ
username = config["DATABASE"]["USERNAME"]
password = config["DATABASE"]["PASSWORD"]
host = config["DATABASE"]["HOST"]
port = config["DATABASE"]["PORT"]
service_name = config["DATABASE"]["SERVICE_NAME"]
table_name = config["DATABASE"]["TABLE_NAME_CV_LANG"]
compartment_id = config["OCI"]["compartment_id"]
dsn = host + ":" + port + "/" + service_name

# LLM íŒŒë¼ë¯¸í„° ì„¤ì • ì¶”ì¶œ
splitter_params = llm_config["splitter_params"]
llm_params = llm_config["llm_params"]
retriever_params = llm_config["retriever_params"]

# Connection Database
try:
    oracledb.init_oracle_client()
    connection = oracledb.connect(user=username, password=password, dsn=dsn)
    print("\nOracle DB Connection successful!\n")
except Exception as e:
    print(f"Oracle DB Connection failed: {e}")
    sys.exit(1)

# Oracle Langchain lib initialization
embedder = OCIGenAIEmbeddings(
    auth_type="INSTANCE_PRINCIPAL",
    model_id="cohere.embed-multilingual-v3.0",
    service_endpoint="https://inference.generativeai.ap-osaka-1.oci.oraclecloud.com",
    compartment_id=compartment_id
)

splitter = OracleTextSplitter(conn=connection, params=splitter_params)
distance_strategy = DistanceStrategy.COSINE
table_name_with_strategy = table_name + '_' + distance_strategy
print("Table Name:", table_name_with_strategy)

# Vector Store Initialization
vector_store = OracleVS(client=connection, embedding_function=embedder, table_name=table_name_with_strategy)

def generate_response(input_text): 
    # LLM ì„¤ì •
    llm = ChatOCIGenAI(
        auth_type="INSTANCE_PRINCIPAL",
        model_id="cohere.command-a-03-2025",
        service_endpoint="https://inference.generativeai.ap-osaka-1.oci.oraclecloud.com",
        compartment_id=compartment_id,
        model_kwargs=llm_params
    )  
    
    # RAG ì²´ì¸ ìƒì„±
    message = [
        (
            "system",
            """
            ì§ˆë¬¸-ë‹µë³€ ì—…ë¬´ë¥¼ ë•ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
            ì¶œì²˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ë°˜ë“œì‹œ ëª…ì‹œí•´ ì£¼ì„¸ìš”.
            ë¬¸ì„œì˜ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ë‹µë³€í•´ ì£¼ì„¸ìš”.:
            \n\n
            {context}",
            """
        ),
        ("human", "{human}"),
    ]
    
    prompt = ChatPromptTemplate.from_messages(message)
    
    chain = {
        "context": vector_store.as_retriever(search_kwargs=retriever_params),
        "human": RunnablePassthrough(),
    } | prompt | llm | StrOutputParser()
    
    # ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
    response = chain.invoke(input_text)
    
    return response



def main():
    print("ğŸ¦œğŸ”— PDF AI Search Application with Oracle Vector Store")
    print("=" * 60)
    print(f"ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • íŒŒì¼: {args.db_config}")
    print(f"LLM íŒŒë¼ë¯¸í„° ì„¤ì • íŒŒì¼: {args.llm_config}")
    print("=" * 60)
    
    try:
        print(f"\nì§ˆë¬¸: {args.question}")
        print("\në‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
        response = generate_response(args.question)
        print(f"\në‹µë³€: {response}")
    except Exception as e:
        print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

if __name__ == "__main__":
    main()
